<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Riding the Data Pipeline</title>
  <link rel="icon" href="https://k-leonard.github.io/Kendall.png" type="image/png" />
  <style>
    body {
      font-family: "Century Schoolbook", serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
      color: #333;
      background-image: url('https://k-leonard.github.io/smallfloral.png');
      background-size: cover;
      background-position: center;
      min-height: 100vh;
    }

    .container {
      width: 80%;
      max-width: 1000px;
      background-color: rgba(255, 255, 255, 0.95);
      padding: 30px 40px;
      margin: 80px auto 40px auto;
      border-radius: 10px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    }

    .navbar {
      background-color: #333;
      width: 100%;
      display: flex;
      justify-content: center;
      position: fixed;
      top: 0;
      left: 0;
      z-index: 1000;
      padding: 10px 0;
    }

    .navbar a {
      color: white;
      padding: 14px 20px;
      text-decoration: none;
      font-size: 18px;
    }

    .navbar a:hover {
      background-color: #ddd;
      color: black;
    }

    h1 {
      text-align: center;
      margin-bottom: 10px;
    }

    .project-subtitle {
      text-align: center;
      font-style: italic;
      color: #555;
      margin-bottom: 30px;
    }

    .project-section {
      margin-bottom: 30px;
    }

    h2 {
      color: #000205;
      margin-bottom: 10px;
      border-bottom: 1px solid #ccc;
      padding-bottom: 5px;
    }

    h3 {
      color: #000205;
      margin-top: 20px;
      margin-bottom: 8px;
    }

    ul {
      padding-left: 20px;
    }

    footer {
      text-align: center;
      margin-top: 40px;
    }

    a.back-link {
      color: #337ab7;
      text-decoration: none;
    }

    a.back-link:hover {
      text-decoration: underline;
    }

    .github-link {
      text-align: center;
      margin-top: 20px;
    }

    .github-link a {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      font-size: 16px;
      text-decoration: none;
      color: #333;
      background-color: #f5f5f5;
      padding: 10px 15px;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    .github-link img {
      width: 28px;
      height: 28px;
    }
 .disclaimer-box {
      background-color: #fff8e1;
      border-left: 5px solid #f0c000;
      padding: 15px 20px;
      border-radius: 8px;
      font-size: 0.95rem;
      color: #555;
      box-shadow: 0 2px 5px rgba(0,0,0,0.05);
      margin-bottom: 30px;
    }
  
  </style>
</head>

<body>
  <div id="navbar-container"></div>


  <div class="container">
    <h1>Riding the Data Pipeline</h1>
    <p class="project-subtitle">A Data Engineering Project on Public Transit Ridership</p>

    <section class="project-section">
      <h2>Overview</h2>
      <p>
        This project delivers an end-to-end data pipeline for analyzing public transportation ridership and fare data.
        The system ingests, processes, and visualizes daily rider behavior and fare usage trends using Airflow, PostgreSQL, and Grafana.
        The goal was to support data-driven decisions around fare policy, rider equity, and system performance while practicing real-world data engineering techniques.
      </p>
    </section>

        <section class="project-section">
      <h2>Project Context & Note</h2>
      <div class="disclaimer-box">
        <p>
          This was a <strong>class-wide collaborative project</strong> built as part of an advanced data engineering course. 
          Each milestone rotated between teams — meaning that my group would begin a new phase using another team’s previous milestone as our starting point. 
          While my team (including Tatum, Jon, and mentor Jed) contributed substantially to multiple phases, the nature of this rotation means that 
          code ownership was shared and iterative. 
        </p>
        <p>
          Additionally, all work was conducted on our professor’s managed server environment, so I do not have direct access to the full source code or logs. 
          The content presented here reflects my team’s architectural contributions, debugging solutions, and analysis deliverables throughout the project.
        </p>
      </div>
    </section>

    <section class="project-section">
      <h2>Skills & Tools Used</h2>
      <ul>
        <li>Python (pandas, psycopg2, boto3, networkx)</li>
        <li>SQL (PostgreSQL, DuckDB)</li>
        <li>Apache Airflow (DAG scheduling, dependency management)</li>
        <li>Grafana (dashboarding, time-series analytics)</li>
        <li>Cloud storage with S3 (MinIO)</li>
        <li>Kafka (real-time event processing)</li>
        <li>GitHub for version control and collaboration</li>
      </ul>
    </section>

    <section class="project-section">
      <h2>Project Breakdown</h2>
      <p><strong>Duration:</strong> January–August 2025<br>
         <strong>Team:</strong> Kendall Leonard, Tatum Good, Jon Garrow, with mentorship/support from Jed Rembold
      </p>

      <h3>What This Project Is</h3>
      <p>
        “Riding the Data Pipeline” is a production-style data engineering initiative for a public transit system.
        We built an automated data infrastructure that ingests ridership and fare data, structures it in a relational warehouse,
        and visualizes system performance through Grafana dashboards. The system simulates real-world data challenges:
        distributed ingestion, schema evolution, incremental updates, and accurate timestamp handling.
      </p>

      <h3>Key Components</h3>
      <ul>
        <li>
          <strong>Automated Ingestion (Airflow):</strong>
          Developed multiple DAGs to extract rider and fare data from APIs and export to MinIO (S3) as JSON/Parquet.
          Tasks used <code>CronDataIntervalTimetable</code> for precise scheduling and custom logging for traceability.
        </li>
        <li>
          <strong>Warehouse Design (PostgreSQL):</strong>
          Created a star-schema warehouse with dimension tables for riders, passengers, fare types, stations, rides, and segments,
          and fact tables for ridership, fares, and durations. Schema evolved to accommodate new features like tap pairing and fare linking.
        </li>
        <li>
          <strong>Transform &amp; Load:</strong>
          Airflow and PostgresHook handled extraction from S3, data normalization, and incremental upserts.
          Type-2 dimension tracking and timezone alignment ensured historical consistency and accuracy across DuckDB and PostgreSQL.
        </li>
        <li>
          <strong>Analytical Workflows:</strong>
          Designed “Business Questions” that guided warehouse logic and analytics:
          <ol>
            <li>Daily and peak ridership patterns</li>
            <li>Fare type equity and distribution</li>
            <li>Ride durations and flow between stations</li>
            <li>High-traffic segments and congestion</li>
            <li>Real-time wait times via Kafka event streams</li>
          </ol>
        </li>
        <li>
          <strong>Dashboards (Grafana):</strong>
          Built interactive dashboards to display key metrics:
          ridership over time, fare type usage, segment congestion, and equity indicators.
          Iterative design feedback led to improved labeling, cleaner comparisons, and standardized color schemes.
        </li>
      </ul>

      <h3>Milestone Highlights</h3>
      <ul>
        <li><strong>M1–M2:</strong> Set up ingestion DAGs and S3 export; designed initial warehouse schema; built baseline ridership KPIs.</li>
        <li><strong>M3:</strong> Implemented ride duration calculations by pairing in/out taps and resolved timezone misalignments.</li>
        <li><strong>M4:</strong> Added NetworkX-based segment mapping and traffic aggregation by segment/date/time.</li>
        <li><strong>M5:</strong> Integrated Kafka train-event streams to compute near-real-time passenger wait times.</li>
      </ul>

      <h3>Challenges &amp; What We Solved</h3>
      <ul>
        <li>
          <strong>Timezone Synchronization:</strong>
          Solved 7-hour timestamp drift caused by inconsistent UTC/local assumptions between Airflow, Python, DuckDB, and PostgreSQL.
        </li>
        <li>
          <strong>Tap Pairing Logic:</strong>
          Developed a matching algorithm to pair passenger entry/exit events and handle incomplete data for accurate duration tracking.
        </li>
        <li>
          <strong>Performance &amp; Memory Management:</strong>
          Used batching, CTEs, and strategic DuckDB transformations to maintain speed and reproducibility with large datasets.
        </li>
        <li>
          <strong>Team Collaboration:</strong>
          Managed version control via GitHub with modular DAG ownership, code reviews, and milestone documentation.
        </li>
      </ul>

      <h3>Outcomes</h3>
      <ul>
        <li>Five fully operational Airflow DAGs for ingestion, transformation, and analytics.</li>
        <li>Normalized, scalable warehouse schema supporting multi-dimensional analysis.</li>
        <li>Grafana dashboards displaying real-time ridership and fare KPIs.</li>
        <li>Kafka integration for live wait-time monitoring.</li>
        <li>Reproducible, transparent workflows with full documentation.</li>
      </ul>

      <h3>What I Learned</h3>
      <p>
        This project deepened my understanding of scalable data pipeline architecture and real-world system integration.
        I learned how to troubleshoot distributed components, coordinate schema changes, and optimize Airflow task execution.
        In the future, I aim to extend the warehouse for multi-year trend modeling and machine learning-based forecasting.
      </p>

      <h3>Links</h3>
      <ul>
        <li>📂 <a href="https://github.com/k-leonard/DataPipeline-Capstone" target="_blank" rel="noopener">GitHub Repository</a></li>
        <li>📊 <a href="#" aria-disabled="true">Grafana Dashboard (Demo)</a> <!-- replace # with live/demo link when ready --></li>
        <li>🧱 <a href="#" aria-disabled="true">ERD &amp; Schema Docs</a> <!-- replace # with ERD page or PDF --></li>
      </ul>
    </section>

    <footer>
      <a class="back-link" href="https://k-leonard.github.io/Website_Assets/Projects.html">← Back to Projects</a>
    </footer>
  </div>

  <script>
    // Load shared navbar
    fetch('https://k-leonard.github.io/navbar.html')
      .then(response => response.text())
      .then(data => {
        document.getElementById('navbar-container').innerHTML = data;
        const script = document.createElement("script");
        script.textContent = `
          function toggleSidebar() {
            const sidebar = document.getElementById("mySidebar");
            sidebar.style.width = (sidebar.style.width === "250px") ? "0" : "250px";
          }
        `;
        document.body.appendChild(script);
      })
      .catch(error => console.error('Error loading the navbar:', error));
  </script>
</body>
</html>
